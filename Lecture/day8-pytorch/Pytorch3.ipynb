{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 人脸识别示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "人脸识别，是基于人的脸部特征信息进行身份识别的一种生物识别技术。通常来说，人脸识别涵盖人脸检测、人脸关键点检测、人脸验证。\n",
    "一个完整的人脸识别流程通常为:人脸检测, 人脸裁剪，人脸对齐，人脸验证。而人脸识别就是和数据库中已有的人脸进行多次人脸验证，来判断该人脸是否在数据库中。在人脸检测中应用较广的算法就是MTCNN（ Multi-task Cascaded Convolutional Networks）。我们在这个例子中主要介绍人脸验证。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![人脸检测](./2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常用的人脸数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 名称 | 人数 | 图片数 |\n",
    "| ---- | ---- | ----|\n",
    "| PubFig | 200 | 58k+ |\n",
    "| CelebA | 10177 | 202599 |\n",
    "| Colorferet | 1000+ | 10000+ |\n",
    "| MTFL | * | 12995 |\n",
    "| FaceDB | 23 | 1521 |\n",
    "| LFW | 5749 | 13233 |\n",
    "| CASIA-Face | 500 | 2500 |\n",
    "| IMDB-WIKI | * | 523051 |\n",
    "| FDDB | * | 2845 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中LFW是人脸验证常用的评价集，其网址为http://vis-www.cs.umass.edu/lfw/ .在下面的示例中，我们将利用该数据集来进行实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 经典深度模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepFace: Closing the Gap to Human-Level Performance in Face Verification\n",
    "\n",
    "DeepFace是最早利用深度学习进行人脸识别的几篇文章之一，发表在2014的CVPR会议上。\n",
    "其主要流程如下：检测，对齐（校正），提取特征，分类。DeepFace利用一个9层深度网络，模型参数1.2亿个。\n",
    "该模型在4000多个不同的人，总计440万张带标记的人脸库中进行训练,在LFW上达到了97.35%的人脸验证精度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DeepFace](./3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Face Representation from Predicting 10,000 Classes \n",
    "\n",
    "DeepID由港中文汤晓鸥团队提出，到现在已有DeepID1,DeepID2,DeepID2+,DeepID3一系列工作。我们简单介绍一下DeepID1(发表在2014CVPR)的思路，其网络模型如下图，其用了10177人，202599张图片用来训练。最终在LFW数据集上达到了97.45%的成绩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DeepID](./4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FaceNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FaceNet: A Unified Embedding for Face Recognition and Clustering\n",
    "\n",
    "该论文发表在2015的CVPR上，该文章最主要的工作是提出了triplet loss,实现了端到端的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FaceNet](./5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "triplet loss 定义为\n",
    "$$ L = \\sum_{i}^{N} \\left[||f(x_i^a)-f(x_i^p)||_2^2 - ||f(x_i^a)-f(x_i^n)||^2_2 + \\alpha \\right]_{+} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们利用LFW数据来进行一个简单的人脸验证实验。我们采用VGG16的网络结构来进行特征提取，然后利用特征之间的欧式距离来判断两张人脸是否属于同一个人。下面重点来介绍以下如何自定义数据类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义数据类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义数据类，首先需要继承Dataset类，然后实现__getitem__和__len__两个函数。通常来说，为了节省内存，我们每次只在训练时才读取当前batch的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def getData(root, name):\n",
    "    with open(os.path.join(root,name), 'r') as file:\n",
    "        paths = [line.split('\\n')[0] for line in file.readlines() if line != '\\n']\n",
    "\n",
    "    classes = list({item.split('/')[0] for item in paths})\n",
    "    classes.sort()\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    \n",
    "    instances = [(os.path.join(root,path), class_to_idx[path.split('/')[0]]) for path in paths]\n",
    "    return instances\n",
    "\n",
    "    \n",
    "class LFW(Dataset):\n",
    "    def __init__(self, root, name,transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        samples = getData(root,name)\n",
    "        self.samples = samples\n",
    "        self.targets = [s[1] for s in samples]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = loader(path)\n",
    "        target = int(target)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "采用VGG16的网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    \n",
    "    def __init__(self, out_dim):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=(1, 1)) \n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=(1, 1)) \n",
    "        self.maxpool1 = nn.MaxPool2d((2, 2)) \n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=(1, 1))\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=(1, 1)) \n",
    "        self.maxpool2 = nn.MaxPool2d((2, 2)) \n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=(1, 1)) \n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=(1, 1)) \n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=(1, 1)) \n",
    "        self.maxpool3 = nn.MaxPool2d((2, 2)) \n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=(1, 1)) \n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.maxpool4 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=(1, 1))\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.maxpool5 = nn.MaxPool2d((2, 2)) \n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, out_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x.size(0)即为batch_size\n",
    "        in_size = x.size(0)\n",
    "        \n",
    "        x = self.conv1_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv1_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x) \n",
    "        \n",
    "        x = self.conv2_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool2(x) \n",
    "        \n",
    "        x = self.conv3_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_3(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool3(x) \n",
    "        \n",
    "        x = self.conv4_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.conv5_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool5(x)\n",
    "        \n",
    "        x = x.view(in_size, -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        feature = self.fc2(x)\n",
    "        x = self.fc3(feature)\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "                \n",
    "        return feature, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑到标签是数字，而非one-hot数据，因此采用nll_loss损失函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.nll_loss(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-46a5b07104fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdagrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adagrad(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.4;accuracy:0.530000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "def getData(root, name):\n",
    "    with open(os.path.join(root,name), 'r') as file:\n",
    "        paths = [line.split('\\n')[0] for line in file.readlines() if line != '\\n']\n",
    "\n",
    "    classes = list({item.split('/')[0] for item in paths})\n",
    "    classes.sort()\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    \n",
    "    instances = [(os.path.join(root,path), class_to_idx[path.split('/')[0]]) for path in paths]\n",
    "    return instances\n",
    "\n",
    "def loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "    \n",
    "class LFW(Dataset):\n",
    "    def __init__(self, root, name,transform=None, target_transform=None):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        samples = getData(root,name)\n",
    "        self.samples = samples\n",
    "        self.targets = [s[1] for s in samples]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.samples[index]\n",
    "        sample = loader(path)\n",
    "        target = int(target)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    \n",
    "class VGG16(nn.Module):\n",
    "    \n",
    "    def __init__(self, out_dim):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(3, 64, 3, padding=(1, 1)) \n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=(1, 1)) \n",
    "        self.maxpool1 = nn.MaxPool2d((2, 2)) \n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=(1, 1))\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=(1, 1)) \n",
    "        self.maxpool2 = nn.MaxPool2d((2, 2)) \n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=(1, 1)) \n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=(1, 1)) \n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=(1, 1)) \n",
    "        self.maxpool3 = nn.MaxPool2d((2, 2)) \n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=(1, 1)) \n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.maxpool4 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=(1, 1))\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=(1, 1)) \n",
    "        self.maxpool5 = nn.MaxPool2d((2, 2)) \n",
    "\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 4096)\n",
    "        self.fc3 = nn.Linear(4096, out_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # x.size(0)即为batch_size\n",
    "        in_size = x.size(0)\n",
    "        \n",
    "        x = self.conv1_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv1_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool1(x) \n",
    "        \n",
    "        x = self.conv2_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv2_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool2(x) \n",
    "        \n",
    "        x = self.conv3_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv3_3(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool3(x) \n",
    "        \n",
    "        x = self.conv4_1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_2(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.conv4_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.conv5_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5_3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.maxpool5(x)\n",
    "        \n",
    "        x = x.view(in_size, -1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        feature = self.fc2(x)\n",
    "        x = self.fc3(feature)\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1)\n",
    "                \n",
    "        return feature, output\n",
    "    \n",
    "    \n",
    "def train(model, device, train_loader, optimizer, epoch, out_dim):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        _, output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "            100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "def val(model, device, val_loader, threshold):\n",
    "    model.eval()\n",
    "    same = 0\n",
    "    dif  = 0\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            features, _ = model(data)\n",
    "            dst = torch.dist(features[0], features[1], p=2)\n",
    "            if dst < threshold:\n",
    "                pred = True\n",
    "            else:\n",
    "                pred = False\n",
    "            \n",
    "            if target[0] == target[1]:\n",
    "                label = True\n",
    "            else:\n",
    "                label = False\n",
    "\n",
    "            if pred == label:\n",
    "                num += 1\n",
    "#             if target[0] == target[1]:\n",
    "#                 same += dst\n",
    "#             else:\n",
    "#                 dif += dst\n",
    "#     print(same)\n",
    "#     print(dif)\n",
    "#     print(same/len(val_loader.dataset))\n",
    "#     print(dif/len(val_loader.dataset))\n",
    "\n",
    "       \n",
    "    print('Threshold: {};accuracy:{:.6f}'.format(threshold, 2*num/len(val_loader.dataset)))\n",
    "    \n",
    "def test(model, device, test_loader, threshold):\n",
    "    model.eval()\n",
    "    num = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            features, _ = model(data)\n",
    "            dst = torch.dist(features[0], features[1], p=2)\n",
    "            if dst < threshold:\n",
    "                pred = True\n",
    "            else:\n",
    "                pred = False\n",
    "            \n",
    "            if target[0] == target[1]:\n",
    "                label = True\n",
    "            else:\n",
    "                label = False\n",
    "\n",
    "            if pred == label:\n",
    "                num += 1\n",
    "    print('Threshold: {};accuracy:{:.6f}'.format(threshold, 2*num/len(val_loader.dataset)))\n",
    "\n",
    "    \n",
    "def main():\n",
    "    # 训练参数\n",
    "    batch_size = 60\n",
    "    test_batch_size = 2\n",
    "    epochs = 10\n",
    "    lr = 0.0001\n",
    "    device = torch.device(\"cuda\")\n",
    "    save_path = './vgg16.pt' \n",
    "    threshold = 0.4\n",
    "    out_dim = 3391\n",
    "    \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    train_data = LFW('lfw_funneled/', 'train.txt', transform=transform)\n",
    "    val_data = LFW('lfw_funneled/', 'val.txt', transform=transform)\n",
    "    test_data = LFW('lfw_funneled/', 'test.txt', transform=transform)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size=2)\n",
    "\n",
    "#     model = VGG16(out_dim).to(device)\n",
    "#     optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
    "\n",
    "#     for epoch in range(1, epochs + 1):\n",
    "#         train(model, device, train_loader, optimizer, epoch, out_dim)\n",
    "#         #test(model, device, test_loader)\n",
    "\n",
    "#     torch.save(model, save_path)\n",
    "    model = torch.load(save_path)\n",
    "    val(model, device, val_loader, threshold)\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
